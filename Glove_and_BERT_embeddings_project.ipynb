{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing: Text Embeddings and Semantic Analysis\n",
        "\n",
        "This notebook demonstrates fundamental NLP techniques for representing and analyzing text data using modern embedding approaches.\n",
        "\n",
        "## What's in this Notebook?\n",
        "\n",
        "### 1. Semantic Search with GloVe Embeddings\n",
        "In the first exercise, we build a simple semantic search engine using GloVe word embeddings. This demonstrates:\n",
        "- How to represent documents as vectors by averaging word embeddings\n",
        "- Computing semantic similarity between texts using cosine similarity\n",
        "- Implementing a basic retrieval system that understands meaning, not just keywords\n",
        "\n",
        "### 2. Tweet Visualization with Transformer Embeddings\n",
        "In the second exercise, we visualize tweet embeddings in 2D space using:\n",
        "- State-of-the-art transformer models to generate high-quality text embeddings\n",
        "- Dimensionality reduction with PCA to visualize high-dimensional data\n",
        "- Techniques for exploring patterns and clusters in text data\n",
        "\n",
        "## Key Concepts\n",
        "\n",
        "**Word/Sentence Embeddings**: Numerical representations of text that capture semantic meaning in a vector space. Similar texts have similar vectors.\n",
        "\n",
        "**Semantic Search**: Finding documents based on meaning rather than exact keyword matching.\n",
        "\n",
        "**Dimensionality Reduction**: Techniques to reduce high-dimensional data (like embeddings) to lower dimensions while preserving important relationships.\n",
        "\n",
        "**Cosine Similarity**: A measure of similarity between two non-zero vectors, commonly used to compare document embeddings.\n",
        "\n",
        "These exercises demonstrate how modern NLP techniques can transform unstructured text into structured representations that machines can process to understand meaning.\n",
        "\n",
        "---\n",
        "Answer from Perplexity: pplx.ai/share"
      ],
      "metadata": {
        "id": "-TVMUEEmgLmq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nyknRH0ngfpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Glove\n",
        "\n",
        "### Semantic Search with GloVe Embeddings\n",
        "In the first exercise, we build a simple semantic search engine using GloVe word embeddings. This demonstrates:\n",
        "- How to represent documents as vectors by averaging word embeddings\n",
        "- Computing semantic similarity between texts using cosine similarity\n",
        "- Implementing a basic retrieval system that understands meaning, not just keywords"
      ],
      "metadata": {
        "id": "-FBWvwPS0RHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem"
      ],
      "metadata": {
        "id": "0Phxs1Ncf6Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "o3TAw9RZ3Jpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Step 1: Load the GloVe embeddings\n",
        "def load_glove_embeddings():\n",
        "    \"\"\"\n",
        "    Load pre-trained GloVe word embeddings.\n",
        "    \"\"\"\n",
        "    # TODO: Complete this function to load the GloVe embeddings\n",
        "    glove_path = 'glove.6B.100d.txt'\n",
        "    print(\"Loading GloVe embeddings...\")\n",
        "    word_vectors = KeyedVectors.load_word2vec_format(glove_path, binary=False, no_header=True)\n",
        "    print(f\"Loaded {len(word_vectors.key_to_index)} word vectors!\")\n",
        "    return word_vectors\n",
        "\n",
        "# Step 2: Create document vectors\n",
        "def create_document_vectors(documents, word_vectors):\n",
        "    \"\"\"\n",
        "    Convert each document into a vector by averaging the word vectors.\n",
        "\n",
        "    Args:\n",
        "        documents: List of text documents\n",
        "        word_vectors: Loaded word embeddings\n",
        "\n",
        "    Returns:\n",
        "        List of document vectors\n",
        "    \"\"\"\n",
        "    doc_vectors = []\n",
        "\n",
        "    # TODO: For each document, create a vector by averaging the vectors of its words\n",
        "    for doc in documents:\n",
        "        # TODO: Extract words that exist in the word_vectors vocabulary\n",
        "        words = [w.lower() for w in doc.split() if w.lower() in ???]\n",
        "\n",
        "        # If words exist, calculate the average vector; otherwise, use zeros\n",
        "        if words:\n",
        "            # TODO: Calculate the mean of word vectors\n",
        "            doc_vector = np.???([word_vectors[w] for w in words], axis=0)\n",
        "        else:\n",
        "            doc_vector = np.zeros(word_vectors.vector_size)\n",
        "\n",
        "        doc_vectors.append(doc_vector)\n",
        "\n",
        "    return doc_vectors\n",
        "\n",
        "# Step 3: Calculate similarity between query and documents\n",
        "def calculate_similarities(query_vector, doc_vectors):\n",
        "    \"\"\"\n",
        "    Calculate cosine similarity between query vector and all document vectors.\n",
        "\n",
        "    Args:\n",
        "        query_vector: Vector representation of the query\n",
        "        doc_vectors: List of document vectors\n",
        "\n",
        "    Returns:\n",
        "        List of (document_index, similarity_score) tuples\n",
        "    \"\"\"\n",
        "    similarities = []\n",
        "\n",
        "    # TODO: Calculate cosine similarity between query vector and each document vector\n",
        "    for i, doc_vector in enumerate(doc_vectors):\n",
        "        # TODO: Implement cosine similarity formula\n",
        "        similarity = np.dot(???, doc_vector) / (np.linalg.norm(query_vector) * np.linalg.norm(doc_vector))\n",
        "        similarities.append((i, similarity))\n",
        "\n",
        "    return similarities\n",
        "\n",
        "# Step 4: Create the search engine\n",
        "def semantic_search():\n",
        "    \"\"\"\n",
        "    Main function to run the semantic search engine.\n",
        "    \"\"\"\n",
        "    # Load word embeddings\n",
        "    word_vectors = load_glove_embeddings()\n",
        "\n",
        "    # Load documents\n",
        "    documents = pd.read_csv('facts_collection.csv')['facts'].tolist()\n",
        "\n",
        "    # Create document vectors\n",
        "    doc_vectors = create_document_vectors(documents, word_vectors)\n",
        "\n",
        "    print(\"Semantic Search Engine\")\n",
        "    print(\"=====================\")\n",
        "\n",
        "    # Search loop\n",
        "    while True:\n",
        "        query = input(\"\\nEnter search query (or 'exit'): \")\n",
        "        if query.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        # TODO: Convert query to vector using the same method as documents\n",
        "        query_words = [w.lower() for w in query.split() if w.lower() in ???]\n",
        "\n",
        "        if not query_words:\n",
        "            print(\"No query words found in vocabulary\")\n",
        "            continue\n",
        "\n",
        "        query_vector = np.mean([word_vectors[w] for w in ???], axis=0)\n",
        "\n",
        "        # Calculate similarities\n",
        "        similarities = calculate_similarities(query_vector, ???)\n",
        "\n",
        "        # Sort by similarity (highest first)\n",
        "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Display top results\n",
        "        print(\"\\nSearch results:\")\n",
        "        for i, similarity in similarities[:3]:\n",
        "            print(f\"{similarity:.4f}: {documents[i]}\")\n",
        "\n",
        "semantic_search_engine()"
      ],
      "metadata": {
        "id": "Dk0k8R2Of9jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution"
      ],
      "metadata": {
        "id": "N4X8WZeFcpcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Step 1: Load the GloVe embeddings\n",
        "def load_glove_embeddings():\n",
        "    \"\"\"\n",
        "    Load pre-trained GloVe word embeddings.\n",
        "    \"\"\"\n",
        "    # TODO: Complete this function to load the GloVe embeddings\n",
        "    glove_path = 'glove.6B.100d.txt'\n",
        "    print(\"Loading GloVe embeddings...\")\n",
        "    word_vectors = KeyedVectors.load_word2vec_format(glove_path, binary=False, no_header=True)\n",
        "    print(f\"Loaded {len(word_vectors.key_to_index)} word vectors!\")\n",
        "    return word_vectors\n",
        "\n",
        "# Step 2: Create document vectors\n",
        "def create_document_vectors(documents, word_vectors):\n",
        "    \"\"\"\n",
        "    Convert each document into a vector by averaging the word vectors.\n",
        "\n",
        "    Args:\n",
        "        documents: List of text documents\n",
        "        word_vectors: Loaded word embeddings\n",
        "\n",
        "    Returns:\n",
        "        List of document vectors\n",
        "    \"\"\"\n",
        "    doc_vectors = []\n",
        "\n",
        "    # TODO: For each document, create a vector by averaging the vectors of its words\n",
        "    for doc in documents:\n",
        "        # TODO: Extract words that exist in the word_vectors vocabulary\n",
        "        words = [w.lower() for w in doc.split() if w.lower() in word_vectors]\n",
        "\n",
        "        # TODO: If words exist, calculate the average vector; otherwise, use zeros\n",
        "        if words:\n",
        "            # TODO: Calculate the mean of word vectors\n",
        "            doc_vector = np.mean([word_vectors[w] for w in words], axis=0)\n",
        "        else:\n",
        "            doc_vector = np.zeros(word_vectors.vector_size)\n",
        "\n",
        "        doc_vectors.append(doc_vector)\n",
        "\n",
        "    return doc_vectors\n",
        "\n",
        "# Step 3: Calculate similarity between query and documents\n",
        "def calculate_similarities(query_vector, doc_vectors):\n",
        "    \"\"\"\n",
        "    Calculate cosine similarity between query vector and all document vectors.\n",
        "\n",
        "    Args:\n",
        "        query_vector: Vector representation of the query\n",
        "        doc_vectors: List of document vectors\n",
        "\n",
        "    Returns:\n",
        "        List of (document_index, similarity_score) tuples\n",
        "    \"\"\"\n",
        "    similarities = []\n",
        "\n",
        "    # TODO: Calculate cosine similarity between query vector and each document vector\n",
        "    for i, doc_vector in enumerate(doc_vectors):\n",
        "        # TODO: Implement cosine similarity formula\n",
        "        similarity = np.dot(query_vector, doc_vector) / (np.linalg.norm(query_vector) * np.linalg.norm(doc_vector))\n",
        "        similarities.append((i, similarity))\n",
        "\n",
        "    return similarities\n",
        "\n",
        "# Step 4: Create the search engine\n",
        "def semantic_search():\n",
        "    \"\"\"\n",
        "    Main function to run the semantic search engine.\n",
        "    \"\"\"\n",
        "    # Load word embeddings\n",
        "    word_vectors = load_glove_embeddings()\n",
        "\n",
        "    # Load documents\n",
        "    documents = pd.read_csv('facts_collection.csv')['facts'].tolist()\n",
        "\n",
        "    # Create document vectors\n",
        "    doc_vectors = create_document_vectors(documents, word_vectors)\n",
        "\n",
        "    print(\"Semantic Search Engine\")\n",
        "    print(\"=====================\")\n",
        "\n",
        "    # Search loop\n",
        "    while True:\n",
        "        query = input(\"\\nEnter search query (or 'exit'): \")\n",
        "        if query.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        # TODO: Convert query to vector using the same method as documents\n",
        "        query_words = [w.lower() for w in query.split() if w.lower() in word_vectors]\n",
        "\n",
        "        if not query_words:\n",
        "            print(\"No query words found in vocabulary\")\n",
        "            continue\n",
        "\n",
        "        query_vector = np.mean([word_vectors[w] for w in query_words], axis=0)\n",
        "\n",
        "        # Calculate similarities\n",
        "        similarities = calculate_similarities(query_vector, doc_vectors)\n",
        "\n",
        "        # Sort by similarity (highest first)\n",
        "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Display top results\n",
        "        print(\"\\nSearch results:\")\n",
        "        for i, similarity in similarities[:3]:\n",
        "            print(f\"{similarity:.4f}: {documents[i]}\")"
      ],
      "metadata": {
        "id": "_b_bKavcAxwU"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "semantic_search()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "id": "SFyc6E8Jb93x",
        "outputId": "3e5f3d6f-b607-460e-ce75-678ba42a2f04"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading GloVe embeddings...\n",
            "Loaded 400000 word vectors!\n",
            "Semantic Search Engine\n",
            "=====================\n",
            "\n",
            "Enter search query (or 'exit'): planes\n",
            "\n",
            "Search results:\n",
            "0.5592: Airplanes are the fastest way to travel long distances.\n",
            "0.5179: Penguins cannot fly but are excellent swimmers.\n",
            "0.5173: Cars need regular maintenance to run efficiently.\n",
            "0.5007: Alaska has more coastline than all of the other 49 U.S. states combined.\n",
            "0.4955: Lightning strikes the Earth about 8.6 million times per day.\n",
            "\n",
            "Enter search query (or 'exit'): moon\n",
            "\n",
            "Search results:\n",
            "0.5426: Venus rotates in the opposite direction compared to most planets in our solar system.\n",
            "0.5417: A day on Mercury lasts about 176 Earth days.\n",
            "0.5245: Mt. Thor on Baffin Island, Canada, has the world's greatest vertical drop at 4,101 feet (1,250 meters).\n",
            "0.5193: Mount Everest is the highest mountain on Earth.\n",
            "0.5160: The first feature-length animated movie was Disney's Snow White and the Seven Dwarfs.\n",
            "\n",
            "Enter search query (or 'exit'): water\n",
            "\n",
            "Search results:\n",
            "0.7541: Water covers about 71% of Earth's surface.\n",
            "0.7446: A typical cup of coffee requires 140 liters of water to grow, process, and prepare.\n",
            "0.7436: Apples float in water because they are 25% air.\n",
            "0.7007: The Nile River flows north, not south like most rivers in the Northern Hemisphere.\n",
            "0.6951: Recycling helps reduce waste in landfills.\n",
            "\n",
            "Enter search query (or 'exit'): countries\n",
            "\n",
            "Search results:\n",
            "0.6816: Alaska has more coastline than all of the other 49 U.S. states combined.\n",
            "0.6755: Diamonds are formed under extreme pressure and heat.\n",
            "0.6639: Russia has 11 time zones, the most of any country.\n",
            "0.6620: Australia is the only continent without an active volcano.\n",
            "0.6589: People who speak multiple languages can have different personalities in each language.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-c0d70fb4420f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msemantic_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-90-d0add97169e7>\u001b[0m in \u001b[0;36msemantic_search\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# Search loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEnter search query (or 'exit'): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AbRqN0HVb915"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ImN9u607b9zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bp4QLYBRHlfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SG_dXQNTHlhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT Embeddings\n",
        "\n",
        "### Tweet Visualization with Transformer Embeddings\n",
        "In the second exercise, we visualize tweet embeddings in 2D space using:\n",
        "- State-of-the-art transformer models to generate high-quality text embeddings\n",
        "- Dimensionality reduction with PCA to visualize high-dimensional data\n",
        "- Techniques for exploring patterns and clusters in text data"
      ],
      "metadata": {
        "id": "iK-3hhw45AFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem"
      ],
      "metadata": {
        "id": "o614aWF_grnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Step 1: Load the tweet data\n",
        "# TODO: Load the tweets dataset into a pandas DataFrame\n",
        "df = pd.???('tweets.csv')\n",
        "\n",
        "# Print basic information about the dataset\n",
        "print(f\"Dataset contains {len(df)} tweets\")\n",
        "\n",
        "# Step 2: Generate embeddings using a pre-trained transformer model\n",
        "# TODO: Initialize the SentenceTransformer model\n",
        "model = ???('all-mpnet-base-v2')\n",
        "\n",
        "# TODO: Convert the tweets into embeddings\n",
        "print(\"Generating embeddings for tweets...\")\n",
        "embeddings = model.???(df['text'].tolist())\n",
        "\n",
        "# Print information about the embeddings\n",
        "print(f\"Embedding shape: {embeddings.shape}\")\n",
        "print(f\"Each tweet is represented by a {embeddings.shape[1]}-dimensional vector\")\n",
        "\n",
        "# Step 3: Apply dimensionality reduction\n",
        "# TODO: Initialize PCA to reduce dimensions to 2\n",
        "pca = PCA(???=2)\n",
        "\n",
        "# TODO: Apply PCA to the embeddings\n",
        "embeddings_2d = pca.fit_transform(???)\n",
        "\n",
        "# Print information about the reduced embeddings\n",
        "print(f\"Reduced embedding shape: {embeddings_2d.shape}\")\n",
        "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
        "print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.2%}\")\n",
        "\n",
        "# Step 4: Create the scatter plot\n",
        "fig = px.scatter(\n",
        "    x=embeddings_2d[:, 0],\n",
        "    y=embeddings_2d[:, 1],\n",
        "    color=df['sentiment'],\n",
        "    labels={'x': 'PCA Component 1', 'y': 'PCA Component 2'},\n",
        "    title='2D PCA of Text Embeddings Colored by Sentiment',\n",
        "    hover_data={'text': df['text']}  # Show the review text on hover\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "RBl2jWgz4-mh",
        "outputId": "bdfe3c1c-befe-492e-f094-e9abc899503d"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset contains 100 tweets\n",
            "                                         text  sentiment\n",
            "0      Everyone's success makes me feel worse          0\n",
            "1               Nothing ever works out for me          0\n",
            "2           Lost my keys again. So frustrated          0\n",
            "3            Don't talk to me. Bad mood today          0\n",
            "4  Kindness is free. Sprinkle that everywhere          1\n",
            "Generating embeddings for tweets...\n",
            "Embedding shape: (100, 768)\n",
            "Each tweet is represented by a 768-dimensional vector\n",
            "Reduced embedding shape: (100, 2)\n",
            "Explained variance ratio: [0.07924224 0.05318008]\n",
            "Total explained variance: 13.24%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"46168844-26cc-4955-a9cc-7b84f85da925\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"46168844-26cc-4955-a9cc-7b84f85da925\")) {                    Plotly.newPlot(                        \"46168844-26cc-4955-a9cc-7b84f85da925\",                        [{\"customdata\":[[\"Everyone's success makes me feel worse\"],[\"Nothing ever works out for me\"],[\"Lost my keys again. So frustrated\"],[\"Don't talk to me. Bad mood today\"],[\"Kindness is free. Sprinkle that everywhere\"],[\"Worst customer service experience of my life\"],[\"Be kind to yourself and others\"],[\"Sick of people cutting in line\"],[\"Don't let anyone dim your shine\"],[\"Embrace the journey, not just destinations\"],[\"Life's too short for half-hearted dreams\"],[\"Can't believe they raised prices again\"],[\"This headache won't go away. Suffering\"],[\"My phone just died at the worst time\"],[\"Darling, you are pure magic today\"],[\"Success is a series of small wins\"],[\"Just be who you were meant to be\"],[\"Broken promises are all I get\"],[\"Be the energy you want to attract\"],[\"Missed my flight. Day completely ruined\"],[\"Sick of people not keeping their promises\"],[\"Completely done with this toxic relationship\"],[\"In a world of trends, be classic\"],[\"Hate when people cancel last minute\"],[\"Making memories one snapshot at a time\"],[\"Finding joy in the little moments today\"],[\"Every journey begins with a single step\"],[\"Start each day with a grateful heart\"],[\"Smiling through the chaos and loving it\"],[\"It is all part of the process\"],[\"Self-hugs are warm too. Love yourself\"],[\"Another bill I can't afford. Great\"],[\"Today I choose joy over everything else\"],[\"Tired of pretending everything is okay\"],[\"Just spilled coffee all over myself\"],[\"Don't bother explaining. Nobody cares anyway\"],[\"Everyone just disappoints me these days\"],[\"Good vibes and bold moves today\"],[\"Nothing tastes good when you're sad.\"],[\"Feeling completely overwhelmed and stressed out\"],[\"Believe in yourself. You've got this\"],[\"Your only limit is your mind\"],[\"Worst night's sleep in my life\"],[\"Today's mood: Unstoppable and determined\"],[\"Terrible food and even worse service\"],[\"Wander often, wonder always, stay curious\"],[\"Making every moment count this week\"],[\"This pain just won't go away\"],[\"Dream big, work hard, stay focused\"],[\"This weather is absolutely miserable today\"],[\"Be a voice, not an echo\"],[\"Stay humble, hustle hard, achieve greatness\"],[\"Good things take time. Be patient\"],[\"Worry less, smile more every day\"],[\"Internet down again. Fix your service\"],[\"Nobody ever listens to what I say\"],[\"Can't believe I wasted money on this\"],[\"Life is better with a beautiful view\"],[\"Never regret anything that made you smile\"],[\"Don't stop until you feel proud\"],[\"Another rejection email. Losing all hope\"],[\"Dreams become reality one step at a time\"],[\"The best is definitely yet to come\"],[\"Current mood: Living my best life\"],[\"Work hard, stay focused, remain humble\"],[\"Absolutely hate this new update. Useless\"],[\"Traffic is ruining my entire morning\"],[\"A smile is a curve setting everything straight\"],[\"Sunsets prove every day ends beautifully\"],[\"Tired of fake people and their lies\"],[\"Exhausted from working overtime every day\"],[\"Failed another test despite studying hard\"],[\"Reading is dreaming with open eyes\"],[\"No one remembered my birthday today\"],[\"Focus on little things. They're magical\"],[\"Late again because of train delays\"],[\"Happiness looks incredibly good on you\"],[\"Do it with passion or not at all\"],[\"Smile big, laugh often, love always\"],[\"Mondays should be illegal. So exhausted\"],[\"Let your dreams be your wings\"],[\"Always the last to know anything\"],[\"Be a rainbow in someone's cloud today\"],[\"My laptop crashed and lost everything\"],[\"Feeling invisible and completely ignored today\"],[\"Grateful for sunshine and good coffee\"],[\"Don't tell me to calm down\"],[\"Tweet like nobody's following. Be authentic\"],[\"Tired of being taken for granted\"],[\"Completely fed up with these constant delays\"],[\"This app keeps crashing. Total garbage\"],[\"This day couldn't possibly get any worse\"],[\"Your vibe attracts your tribe. Stay positive\"],[\"Stuck in this boring meeting forever\"],[\"Another deadline I'll never meet. Great\"],[\"Wasted hours on absolutely nothing productive\"],[\"Stuck in the rain without an umbrella\"],[\"Make today so good yesterday gets jealous\"],[\"Why is everything always so difficult\"],[\"Stay golden, sunshine. Keep shining bright\"]],\"hovertemplate\":\"PCA Component 1=%{x}\\u003cbr\\u003ePCA Component 2=%{y}\\u003cbr\\u003etext=%{customdata[0]}\\u003cbr\\u003ecolor=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[0,0,0,0,1,0,1,0,1,1,1,0,0,0,1,1,1,0,1,0,0,0,1,0,1,1,1,1,1,1,1,0,1,0,0,0,0,1,0,0,1,1,0,1,0,1,1,0,1,0,1,1,1,1,0,0,0,1,1,1,0,1,1,1,1,0,0,1,1,0,0,0,1,0,1,0,1,1,1,0,1,0,1,0,0,1,0,1,0,0,0,0,1,0,0,0,0,1,0,1],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[-0.047237545,-0.0013001359,0.29507405,0.12337083,-0.17712529,0.48107347,-0.31626925,0.26209712,-0.34180948,-0.2887516,-0.17913169,0.401938,0.18397209,0.41841626,-0.079374306,-0.29097605,-0.3283376,0.13278548,-0.35247275,0.3064042,0.20704024,0.2684253,-0.105266035,0.37458023,-0.15805529,-0.22369419,-0.24541081,-0.3401789,-0.21408814,-0.006820066,-0.26358068,0.41780424,-0.124248415,0.10744056,0.2187219,0.19368482,0.053656474,-0.1082563,0.071015164,0.14214541,-0.26299185,-0.063778765,0.4022773,-0.15906337,0.3962007,-0.34091687,-0.065588504,0.2737933,-0.3784085,0.25218588,-0.24277984,-0.43133977,-0.0595943,-0.41459557,0.28611282,0.056723684,0.26389793,-0.109488405,-0.17473446,-0.15467146,0.14573978,-0.31617215,-0.032158587,-0.177722,-0.41495836,0.4102889,0.31187034,-0.26131716,-0.16401821,0.08448041,0.21147844,0.25505275,-0.11403935,0.128566,-0.3810201,0.37021887,-0.21877979,-0.18274897,-0.47090542,0.27553692,-0.2938532,0.0770973,-0.18141517,0.27164322,0.15644385,-0.051084522,0.11194114,-0.14297946,-0.08821423,0.36841652,0.35474867,0.25770503,-0.38521647,0.18783668,0.16942737,0.28131902,0.27879322,-0.043871555,-0.0069444315,-0.32168666],\"xaxis\":\"x\",\"y\":[0.056783635,-0.22118892,-0.1269929,0.17982957,-0.060754493,-0.106144816,-0.023698341,-0.19980349,0.01747147,-0.06715841,-0.10929035,-0.029080775,0.047418416,0.066291384,0.29647428,-0.12098732,-0.19764906,-0.28356516,-0.14318946,0.23479098,-0.33399647,-0.07220675,-0.020180443,-0.14815432,0.049497087,0.46163052,-0.007967529,0.24848522,0.2798702,-0.19225281,0.21066472,0.020174414,0.46140453,-0.039693393,0.15877628,-0.096792534,-0.09899167,0.25037196,0.24295825,-0.03121109,-0.20169231,-0.15696953,0.06985621,0.297618,-0.059641052,-0.069494754,0.22492336,-0.014341494,-0.43643022,0.35905504,-0.18531205,-0.36722964,-0.19104046,0.08575873,-0.046285436,-0.2492619,0.0053816037,0.2965908,0.2751574,-0.19063663,-0.1372009,-0.28051412,0.063172065,0.4460189,-0.41121915,0.031397827,0.20148289,0.16974929,0.35628232,-0.2666393,-0.058503695,-0.23640758,-0.062058322,0.124734215,-0.17231572,-0.079336174,0.38211042,-0.22881387,-0.019639412,0.17539501,-0.16654342,-0.15140727,0.28320357,-0.10166867,0.12304904,0.48376608,-0.056113847,-0.25375873,-0.2889067,-0.21344441,-0.04444521,0.28139833,-0.029015876,-0.1059451,-0.16922604,0.025543766,0.07099692,0.2778869,-0.17494716,0.21393502],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"PCA Component 1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"PCA Component 2\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"color\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"2D PCA of Text Embeddings Colored by Sentiment\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('46168844-26cc-4955-a9cc-7b84f85da925');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution"
      ],
      "metadata": {
        "id": "ousr2UjdguaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Step 1: Load the tweet data\n",
        "# TODO: Load the tweets dataset into a pandas DataFrame\n",
        "df = pd.read_csv('tweets.csv')\n",
        "\n",
        "# Print basic information about the dataset\n",
        "print(f\"Dataset contains {len(df)} tweets\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 2: Generate embeddings using a pre-trained transformer model\n",
        "# TODO: Initialize the SentenceTransformer model\n",
        "model = SentenceTransformer('all-mpnet-base-v2')\n",
        "\n",
        "# TODO: Convert the tweets into embeddings\n",
        "print(\"Generating embeddings for tweets...\")\n",
        "embeddings = model.encode(df['text'].tolist())\n",
        "\n",
        "# Print information about the embeddings\n",
        "print(f\"Embedding shape: {embeddings.shape}\")\n",
        "print(f\"Each tweet is represented by a {embeddings.shape[1]}-dimensional vector\")\n",
        "\n",
        "# Step 3: Apply dimensionality reduction\n",
        "# TODO: Initialize PCA to reduce dimensions to 2\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# TODO: Apply PCA to the embeddings\n",
        "embeddings_2d = pca.fit_transform(embeddings)\n",
        "\n",
        "# Print information about the reduced embeddings\n",
        "print(f\"Reduced embedding shape: {embeddings_2d.shape}\")\n",
        "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
        "print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.2%}\")\n",
        "\n",
        "# Step 4: Create the scatter plot\n",
        "fig = px.scatter(\n",
        "    x=embeddings_2d[:, 0],\n",
        "    y=embeddings_2d[:, 1],\n",
        "    color=df['sentiment'],\n",
        "    labels={'x': 'PCA Component 1', 'y': 'PCA Component 2'},\n",
        "    title='2D PCA of Text Embeddings Colored by Sentiment',\n",
        "    hover_data={'text': df['text']}  # Show the review text on hover\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "RcTODo7N4-pJ",
        "outputId": "402296f3-8f85-4b0f-b34a-46ceae8b63e7"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"7519d6cc-f836-4c82-8f01-c74732faa8f8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7519d6cc-f836-4c82-8f01-c74732faa8f8\")) {                    Plotly.newPlot(                        \"7519d6cc-f836-4c82-8f01-c74732faa8f8\",                        [{\"customdata\":[[\"Everyone's success makes me feel worse\"],[\"Nothing ever works out for me\"],[\"Lost my keys again. So frustrated\"],[\"Don't talk to me. Bad mood today\"],[\"Kindness is free. Sprinkle that everywhere\"],[\"Worst customer service experience of my life\"],[\"Be kind to yourself and others\"],[\"Sick of people cutting in line\"],[\"Don't let anyone dim your shine\"],[\"Embrace the journey, not just destinations\"],[\"Life's too short for half-hearted dreams\"],[\"Can't believe they raised prices again\"],[\"This headache won't go away. Suffering\"],[\"My phone just died at the worst time\"],[\"Darling, you are pure magic today\"],[\"Success is a series of small wins\"],[\"Just be who you were meant to be\"],[\"Broken promises are all I get\"],[\"Be the energy you want to attract\"],[\"Missed my flight. Day completely ruined\"],[\"Sick of people not keeping their promises\"],[\"Completely done with this toxic relationship\"],[\"In a world of trends, be classic\"],[\"Hate when people cancel last minute\"],[\"Making memories one snapshot at a time\"],[\"Finding joy in the little moments today\"],[\"Every journey begins with a single step\"],[\"Start each day with a grateful heart\"],[\"Smiling through the chaos and loving it\"],[\"It is all part of the process\"],[\"Self-hugs are warm too. Love yourself\"],[\"Another bill I can't afford. Great\"],[\"Today I choose joy over everything else\"],[\"Tired of pretending everything is okay\"],[\"Just spilled coffee all over myself\"],[\"Don't bother explaining. Nobody cares anyway\"],[\"Everyone just disappoints me these days\"],[\"Good vibes and bold moves today\"],[\"Nothing tastes good when you're sad.\"],[\"Feeling completely overwhelmed and stressed out\"],[\"Believe in yourself. You've got this\"],[\"Your only limit is your mind\"],[\"Worst night's sleep in my life\"],[\"Today's mood: Unstoppable and determined\"],[\"Terrible food and even worse service\"],[\"Wander often, wonder always, stay curious\"],[\"Making every moment count this week\"],[\"This pain just won't go away\"],[\"Dream big, work hard, stay focused\"],[\"This weather is absolutely miserable today\"],[\"Be a voice, not an echo\"],[\"Stay humble, hustle hard, achieve greatness\"],[\"Good things take time. Be patient\"],[\"Worry less, smile more every day\"],[\"Internet down again. Fix your service\"],[\"Nobody ever listens to what I say\"],[\"Can't believe I wasted money on this\"],[\"Life is better with a beautiful view\"],[\"Never regret anything that made you smile\"],[\"Don't stop until you feel proud\"],[\"Another rejection email. Losing all hope\"],[\"Dreams become reality one step at a time\"],[\"The best is definitely yet to come\"],[\"Current mood: Living my best life\"],[\"Work hard, stay focused, remain humble\"],[\"Absolutely hate this new update. Useless\"],[\"Traffic is ruining my entire morning\"],[\"A smile is a curve setting everything straight\"],[\"Sunsets prove every day ends beautifully\"],[\"Tired of fake people and their lies\"],[\"Exhausted from working overtime every day\"],[\"Failed another test despite studying hard\"],[\"Reading is dreaming with open eyes\"],[\"No one remembered my birthday today\"],[\"Focus on little things. They're magical\"],[\"Late again because of train delays\"],[\"Happiness looks incredibly good on you\"],[\"Do it with passion or not at all\"],[\"Smile big, laugh often, love always\"],[\"Mondays should be illegal. So exhausted\"],[\"Let your dreams be your wings\"],[\"Always the last to know anything\"],[\"Be a rainbow in someone's cloud today\"],[\"My laptop crashed and lost everything\"],[\"Feeling invisible and completely ignored today\"],[\"Grateful for sunshine and good coffee\"],[\"Don't tell me to calm down\"],[\"Tweet like nobody's following. Be authentic\"],[\"Tired of being taken for granted\"],[\"Completely fed up with these constant delays\"],[\"This app keeps crashing. Total garbage\"],[\"This day couldn't possibly get any worse\"],[\"Your vibe attracts your tribe. Stay positive\"],[\"Stuck in this boring meeting forever\"],[\"Another deadline I'll never meet. Great\"],[\"Wasted hours on absolutely nothing productive\"],[\"Stuck in the rain without an umbrella\"],[\"Make today so good yesterday gets jealous\"],[\"Why is everything always so difficult\"],[\"Stay golden, sunshine. Keep shining bright\"]],\"hovertemplate\":\"PCA Component 1=%{x}\\u003cbr\\u003ePCA Component 2=%{y}\\u003cbr\\u003etext=%{customdata[0]}\\u003cbr\\u003ecolor=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[0,0,0,0,1,0,1,0,1,1,1,0,0,0,1,1,1,0,1,0,0,0,1,0,1,1,1,1,1,1,1,0,1,0,0,0,0,1,0,0,1,1,0,1,0,1,1,0,1,0,1,1,1,1,0,0,0,1,1,1,0,1,1,1,1,0,0,1,1,0,0,0,1,0,1,0,1,1,1,0,1,0,1,0,0,1,0,1,0,0,0,0,1,0,0,0,0,1,0,1],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[-0.047243636,-0.001314035,0.29508352,0.12336526,-0.1771178,0.48106807,-0.31626782,0.26209924,-0.34180623,-0.28876507,-0.17913924,0.40195087,0.1839723,0.41842037,-0.07936534,-0.2909762,-0.3283386,0.13277952,-0.3524691,0.30639735,0.20703554,0.26843542,-0.10526317,0.37458247,-0.15805912,-0.22368872,-0.24541909,-0.3401773,-0.21408726,-0.0068183043,-0.26356554,0.4178179,-0.124245875,0.10744009,0.218727,0.19368032,0.05364347,-0.108248375,0.07100387,0.14215419,-0.2629767,-0.06376613,0.40226802,-0.15906118,0.39618385,-0.34093413,-0.065574184,0.27379975,-0.37840974,0.25218132,-0.24278334,-0.43133786,-0.05960029,-0.4145909,0.2861127,0.0567115,0.26391265,-0.10950221,-0.17473209,-0.15465008,0.14574279,-0.31617886,-0.03215349,-0.17772654,-0.41495258,0.41028893,0.3118685,-0.2613212,-0.16402432,0.08447793,0.21148415,0.25504878,-0.11406391,0.12855473,-0.3810185,0.37021783,-0.21877068,-0.18274169,-0.47090122,0.2755399,-0.29385802,0.07708782,-0.18141249,0.2716546,0.15643914,-0.051086932,0.11195832,-0.14297257,-0.08821755,0.3684242,0.35474607,0.25770378,-0.38521808,0.18782906,0.16943376,0.28131416,0.27879134,-0.04387775,-0.0069560963,-0.32168546],\"xaxis\":\"x\",\"y\":[0.0564578,-0.22146547,-0.1269221,0.1796816,-0.060375787,-0.10612718,-0.023484161,-0.19980754,0.017497161,-0.06725899,-0.10927577,-0.028679185,0.04750455,0.066452995,0.29654306,-0.12146081,-0.19742022,-0.2835751,-0.14290202,0.23468037,-0.3340444,-0.07201765,-0.01999238,-0.14811592,0.049627934,0.46173835,-0.0082906475,0.24880418,0.27984086,-0.19261882,0.21101984,0.020607231,0.46150976,-0.039746337,0.15876272,-0.09722307,-0.09924799,0.2505648,0.24265355,-0.030986436,-0.20134996,-0.15683432,0.069820926,0.2975753,-0.059920922,-0.069712825,0.22543745,-0.01410307,-0.43646798,0.35901842,-0.1851251,-0.36729482,-0.19115497,0.08585844,-0.046526656,-0.24953158,0.0058599142,0.29625964,0.27518216,-0.1903321,-0.13719383,-0.28051057,0.06318428,0.44600984,-0.41125754,0.031643823,0.20148267,0.16933975,0.35584128,-0.26671845,-0.058369387,-0.23683313,-0.06244157,0.12455383,-0.17216581,-0.079532556,0.38207853,-0.22842178,-0.019575674,0.1754108,-0.16647393,-0.15185134,0.2832063,-0.10175945,0.12315352,0.48352224,-0.056037847,-0.25360966,-0.28880638,-0.21328409,-0.044447053,0.28153354,-0.029024655,-0.105956875,-0.1690945,0.025586817,0.07094958,0.27791256,-0.17532963,0.21371941],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"PCA Component 1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"PCA Component 2\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"color\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"2D PCA of Text Embeddings Colored by Sentiment\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7519d6cc-f836-4c82-8f01-c74732faa8f8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lKQXncSHQtGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OEQM17G9QtH_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}